{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 單獨做CNN 的部分"
      ],
      "metadata": {
        "id": "aMGXAMAfCDwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RegBXPC8AAdH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import datetime as dt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#抓取特定時間\n",
        "stock_id = '3711.TW'\n",
        "start = dt.datetime(2020,1,1)\n",
        "end   = dt.datetime(2024, 10,10 )\n",
        "data = yf.download(stock_id, start= start, end=end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VELPV_4VCCbv",
        "outputId": "44b6002c-0fa8-4365-c426-1d7e02552fc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.reset_index()\n",
        "data['Date'] = pd.to_datetime(data['Date']) ## 讓她是時間間數據。\n",
        "data['Date'] = data['Date'].dt.strftime('%Y_%m_%d')\n",
        "data = data.droplevel('Ticker', axis=1) # 刪除 `Ticker` 這層索引\n",
        "data =data.drop(columns=['Adj Close'])  # 這是需要寫等於的。\n",
        "data['Next_close'] = data['Close'].shift(-1) ## 將Close 欄位向上移動一行， 這樣'Next_Close' 會是下一天收盤價。\n",
        "data['Diff'] = (data['Next_close'] > data['Close']).astype('int') ## 比較 'Next_Close' 和 'Close'，大於為1 ， 小於為0。 1代表漲的意識， 0 代表跌的意識。\n"
      ],
      "metadata": {
        "id": "ILrrhgB-CCeZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 準備劃K線圖的資料。\n",
        "twenty_days = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(data.values) -20):\n",
        "    segment = data[['Open','High','Low','Close']].values[i:i+20]\n",
        "    twenty_days.append(segment)\n",
        "    labels.append(data[['Date','Diff']].values[i+19]) #他要是到19 就有答案了。\n"
      ],
      "metadata": {
        "id": "6Q8ZbpGmCCjY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% ## 我要去畫K  線圖。\n",
        "\n",
        "image_path = './CNN_data/image'\n",
        "os.makedirs(image_path, exist_ok=True)\n",
        "\n",
        "for idx, segment in enumerate(twenty_days):\n",
        "    #print(segment) ## 這個要在進去一次取才能取道 open，close ... 這些資料。\n",
        "    fig, ax = plt.subplots() # 設置圖像大小（英寸）和 DPI\n",
        "    fig.set_size_inches(0.5, 0.5)\n",
        "    for day_idx ,day in enumerate(segment):\n",
        "        Open_price, high_price , low_price, Close_price = map(int, day)\n",
        "        color = \"red\" if Close_price > Open_price else \"green\"\n",
        "\n",
        "        plt.bar(day_idx, abs(Close_price - Open_price), bottom=min(Open_price, Close_price), color=color, width=0.5)\n",
        "        plt.bar(day_idx, high_price - low_price, bottom=low_price,color=color, width=0.1 )\n",
        "\n",
        "    rise_or_fall = \"rise\" if labels[idx][1] ==1 else \"fail\"\n",
        "    Datatime =  labels[idx][0]\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f'{image_path}/{idx:05d}_{Datatime}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "ET-3a8oJCClu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Dataset Preparation\n",
        "print('Dataset Preparation Start')\n",
        "image_files = os.listdir(image_path)\n",
        "train_size = int(len(image_files) * 0.8 )\n",
        "train_list = image_files[:train_size]\n",
        "test_list  = image_files[train_size: ]\n",
        "\n",
        "\n",
        "train_rise_folder = './CNN_data/train_folder_path/rise'\n",
        "train_fail_folder = './CNN_data/train_folder_path/fail'\n",
        "test_rise_folder = './CNN_data/test_folder_path/rise'\n",
        "test_fail_folder = './CNN_data/test_folder_path/fail'\n",
        "\n",
        "for folder in [train_rise_folder, train_fail_folder, test_rise_folder, test_fail_folder]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "\n",
        "## 複製train 圖片到 train資料夾。\n",
        "for train_image in train_list:\n",
        "    scr_path = os.path.join('./CNN_data/image', train_image)\n",
        "    #print(scr_path) ##./image\\00368_2024_08_09_rise.png  多思，為什麼他是長這樣呀????\n",
        "    rise_fail_str = str(scr_path).split('_')\n",
        "    #print(rise_fail_str[4][0:4]) ## 取出 'rise' 或 false 字體\n",
        "    #print(rise_fail_str)\n",
        "    if rise_fail_str[5][0:4] == \"rise\" :\n",
        "        dest_path = os.path.join(train_rise_folder+'/', train_image)\n",
        "    if rise_fail_str[5][0:4] == \"fail\" :\n",
        "        dest_path = os.path.join(train_fail_folder+'/', train_image)\n",
        "    shutil.copy(scr_path, dest_path)\n",
        "\n",
        "##複製test 圖片到 test 資料夾\n",
        "for test_image in test_list:\n",
        "    scr_path = os.path.join('./CNN_data/image', test_image)\n",
        "    rise_fail_str = str(scr_path).split('_')\n",
        "    if rise_fail_str[5][0:4] == \"rise\" :\n",
        "        dest_path = os.path.join(test_rise_folder+'/', test_image)\n",
        "    if rise_fail_str[5][0:4] == \"fail\" :\n",
        "        dest_path = os.path.join(test_fail_folder+'/', test_image)\n",
        "    shutil.copy(scr_path, dest_path)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4xNnap-CZmf",
        "outputId": "1afff51b-d36e-442c-ae81-72fec4e87de4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preparation Start\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%  ## 接著我要建立CNN 模型\n",
        "print(\"接著我要建立CNN 模型\")\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#檢查GPU 是否可用\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device: \", device) ## 顯示使用的裝置。\n",
        "\n",
        "#定義轉換\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((50, 50)),  ##調整圖片大小\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#讀取訓練和驗證資料夾\n",
        "train_data = datasets.ImageFolder(root='./CNN_data/train_folder_path/', transform= transform)\n",
        "test_data = datasets.ImageFolder(root='./CNN_data/test_folder_path/', transform= transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Model, self).__init__() ## 要繼承他的爸爸\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size =3 , stride=1, padding=0), #(50 * 50) -> (48 * 48)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (48, 48) -> (24, 24)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 32, out_channels = 48, kernel_size = 3, stride=1, padding=0), #(24, 24) -> (22, 22)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (22, 22) -> (11, 11)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 48, out_channels = 64, kernel_size = 3, stride=1, padding=0),   #(11,11) -> (9,9)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (9,9) -> (4,4)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 64, out_channels = 96, kernel_size =3, stride=1, padding=0),   #(4,4) -> (2,2)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  #(2* 2) -> (1 * 1)\n",
        "            nn.ReLU()\n",
        "            )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features= 96, out_features= 64),\n",
        "            nn.Linear(in_features = 64, out_features = 32),\n",
        "            nn.Linear(in_features= 32, out_features= 1),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        cnn_out = out.view(out.size(0), -1)  #3 多思，我這樣攤平對嗎?\n",
        "        linear_out = self.linear(cnn_out)\n",
        "\n",
        "        return linear_out\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaUVROYvC5MB",
        "outputId": "4046b554-9f0d-4c33-efa2-1ef99f7d503b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "接著我要建立CNN 模型\n",
            "Using device:  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = CNN_Model()\n",
        "print(model)\n",
        "\n",
        "# 初始化模型並轉移至 GPU\n",
        "model = CNN_Model().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_func = nn.BCELoss()\n",
        "input_shape = (-1,3,50,50)  ##多思，這個要幹嘛?\n",
        "\n",
        "# Traning the Model\n",
        "#history-like list for store loss & acc value\n",
        "training_loss_list = []\n",
        "num_epochs = 50\n",
        "\n",
        "# 開始訓練 訓練集\n",
        "print(\"開始訓練 訓練集\")\n",
        "for epoch in range(num_epochs) :\n",
        "    #print('epoch: ', epoch)\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i , (image, label) in enumerate(train_loader):\n",
        "        images, labels = image.to(device), label.to(device) # 將 images 和 labels 轉移至 GPU\n",
        "        #print(images.shape)\n",
        "        #print(labels.shape)\n",
        "        optimizer.zero_grad() # 2.Clear gradients  ## 清晰的漸變; 清理梯度\n",
        "        #images = images.view(input_shape)\n",
        "\n",
        "        outputs = model(images) # 3.Forward propagation ##前向傳播\n",
        "        outputs = outputs.squeeze(-1)  # 移除最後一個維度 [16,1] -> [16] # 適用於 BCELoss 的輸出\n",
        "\n",
        "        train_loss = loss_func(outputs, labels.float()) # 4.Calculate softmax and cross entropy loss  ## 計算softmax和交叉熵損失\n",
        "        train_loss.backward()  # 5.Calculate gradients #計算梯度\n",
        "        optimizer.step() # 6.Update parameters  ##更新參數\n",
        "        running_loss += train_loss.item()\n",
        "\n",
        "    # 計算訓練準確率\n",
        "    avg_loss =  running_loss / len(train_loader)\n",
        "    print(f\"epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.7f} \")\n",
        "    training_loss_list.append(avg_loss)\n",
        "\n",
        "## 儲存模型\n",
        "torch.save(model,'./CNN_data/CNN_model_test1.pt')\n",
        "\n",
        "## 測試集\n",
        "# 驗證模型\n",
        "\n",
        "test_loss_lsit = []\n",
        "test_accuracy = []\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device) # 將 images 和 labels 轉移至 GPU\n",
        "        outputs = model(images)\n",
        "        outputs = outputs.squeeze(-1)\n",
        "        #計算損失\n",
        "        loss = loss_func(outputs, labels.float())\n",
        "        test_loss += loss.item()\n",
        "\n",
        "\n",
        "        ## 計算準確率\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.float()).sum().item()\n",
        "        #print(predicted, labels)\n",
        "\n",
        "## 儲存測試損失準確度\n",
        "avg_loss = test_loss/len(test_loader)\n",
        "#print(f'Test Loss: {avg_loss:.4f}')\n",
        "#print(len(test_loader))\n",
        "\n",
        "test_loss_lsit.append(avg_loss)\n",
        "accuracy_on_testData =  correct / total * 100\n",
        "print(f'Accuracy on test data: {accuracy_on_testData:.2f}%')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iMwF0j_C5JV",
        "outputId": "55b9e52d-f372-499c-b71f-cc45c625676e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_Model(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU()\n",
            "    (6): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): ReLU()\n",
            "    (9): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): ReLU()\n",
            "  )\n",
            "  (linear): Sequential(\n",
            "    (0): Linear(in_features=96, out_features=64, bias=True)\n",
            "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n",
            "開始訓練 訓練集\n",
            "epoch [1/50], Loss: 0.6939301 \n",
            "epoch [2/50], Loss: 0.6934324 \n",
            "epoch [3/50], Loss: 0.6936309 \n",
            "epoch [4/50], Loss: 0.6935431 \n",
            "epoch [5/50], Loss: 0.6930288 \n",
            "epoch [6/50], Loss: 0.6927927 \n",
            "epoch [7/50], Loss: 0.6930569 \n",
            "epoch [8/50], Loss: 0.6934086 \n",
            "epoch [9/50], Loss: 0.6932923 \n",
            "epoch [10/50], Loss: 0.6936519 \n",
            "epoch [11/50], Loss: 0.6929561 \n",
            "epoch [12/50], Loss: 0.6930986 \n",
            "epoch [13/50], Loss: 0.6928143 \n",
            "epoch [14/50], Loss: 0.6931402 \n",
            "epoch [15/50], Loss: 0.6932485 \n",
            "epoch [16/50], Loss: 0.6929632 \n",
            "epoch [17/50], Loss: 0.6931903 \n",
            "epoch [18/50], Loss: 0.6928517 \n",
            "epoch [19/50], Loss: 0.6931792 \n",
            "epoch [20/50], Loss: 0.6928094 \n",
            "epoch [21/50], Loss: 0.6931135 \n",
            "epoch [22/50], Loss: 0.6933989 \n",
            "epoch [23/50], Loss: 0.6928534 \n",
            "epoch [24/50], Loss: 0.6932767 \n",
            "epoch [25/50], Loss: 0.6930629 \n",
            "epoch [26/50], Loss: 0.6930830 \n",
            "epoch [27/50], Loss: 0.6931151 \n",
            "epoch [28/50], Loss: 0.6930906 \n",
            "epoch [29/50], Loss: 0.6928989 \n",
            "epoch [30/50], Loss: 0.6932041 \n",
            "epoch [31/50], Loss: 0.6932724 \n",
            "epoch [32/50], Loss: 0.6929443 \n",
            "epoch [33/50], Loss: 0.6931046 \n",
            "epoch [34/50], Loss: 0.6929931 \n",
            "epoch [35/50], Loss: 0.6930047 \n",
            "epoch [36/50], Loss: 0.6930298 \n",
            "epoch [37/50], Loss: 0.6931824 \n",
            "epoch [38/50], Loss: 0.6930450 \n",
            "epoch [39/50], Loss: 0.6929767 \n",
            "epoch [40/50], Loss: 0.6928646 \n",
            "epoch [41/50], Loss: 0.6931866 \n",
            "epoch [42/50], Loss: 0.6930022 \n",
            "epoch [43/50], Loss: 0.6931454 \n",
            "epoch [44/50], Loss: 0.6931562 \n",
            "epoch [45/50], Loss: 0.6927946 \n",
            "epoch [46/50], Loss: 0.6928366 \n",
            "epoch [47/50], Loss: 0.6931508 \n",
            "epoch [48/50], Loss: 0.6930181 \n",
            "epoch [49/50], Loss: 0.6931155 \n",
            "epoch [50/50], Loss: 0.6930694 \n",
            "Accuracy on test data: 51.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(num_epochs), training_loss_list, 'b-', label='Training_loss')\n",
        "plt.title('Training  loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "39oEbtI1C5Gt",
        "outputId": "364b2778-2049-4e09-a4d1-c85c0028e9e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjXsgK-yC5Ep"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.單獨做LSTM的話"
      ],
      "metadata": {
        "id": "NUMRDSauEtYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awqt80YCE55J",
        "outputId": "00706bac-e14d-485b-c43b-2ab1b2ba22a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands\n",
        "import datetime as dt"
      ],
      "metadata": {
        "id": "KDmbhPBwEz23"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_id = '3711.TW'\n",
        "\n",
        "#抓取特定時間\n",
        "start = dt.datetime(2020,1,1)\n",
        "end   = dt.datetime(2024, 10,10 )\n",
        "data = yf.download(stock_id, start= start, end=end)\n",
        "\n",
        "data = data.reset_index()\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Date'] = data['Date'].dt.strftime('%Y_%m_%d')\n",
        "\n",
        "data = data.droplevel('Ticker', axis=1) # 刪除 `Ticker` 這層索引\n",
        "data =data.drop(columns=['Adj Close'])  # 這是需要寫等於的。\n",
        "\n",
        "\n",
        "# 加入目標變數 (Diff)\n",
        "data['Next_close'] = data['Close'].shift(-1)\n",
        "data['Diff'] = (data['Next_close'] > data['Close']).astype('int')\n",
        "data = data.dropna()  # 確保沒有 NaN 資料\n",
        "\n",
        "# 加入技術指標\n",
        "data['SMA_5'] = data['Close'].rolling(window=5).mean()\n",
        "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
        "\n",
        "rsi = RSIIndicator(close=data['Close'], window=14)\n",
        "data['RSI_14'] = rsi.rsi()\n",
        "\n",
        "macd = MACD(close=data['Close'])\n",
        "data['MACD'] = macd.macd()\n",
        "data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "bb = BollingerBands(close=data['Close'], window=20, window_dev=2)\n",
        "data['BB_upper'] = bb.bollinger_hband()\n",
        "data['BB_lower'] = bb.bollinger_lband()\n",
        "data['BB_width'] = data['BB_upper'] - data['BB_lower']\n",
        "\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S0k14W1E3E-",
        "outputId": "1d91e8df-6a19-450d-9283-f3ec66e23be1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 滑動窗口生成特徵和標籤\n",
        "twenty_days = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(data.values) - 20):\n",
        "    segment = data[['Open', 'High', 'Low', 'Close', 'Volume',\n",
        "                    'SMA_5', 'SMA_20', 'RSI_14', 'MACD', 'BB_width']].values[i:i + 20]\n",
        "    twenty_days.append(segment)\n",
        "    labels.append(data['Diff'].values[i + 19])\n",
        "\n",
        "# 分割訓練和測試集\n",
        "train_size = int(len(labels) * 0.8)\n",
        "\n",
        "train_x = np.array(twenty_days[:train_size], dtype=np.float32)\n",
        "test_x = np.array(twenty_days[train_size:], dtype=np.float32)\n",
        "\n",
        "train_y = np.array(labels[:train_size], dtype=np.float32)\n",
        "test_y = np.array(labels[train_size:], dtype=np.float32)\n",
        "\n",
        "# 轉換為 Torch 張量\n",
        "train_x = torch.FloatTensor(train_x)\n",
        "test_x = torch.FloatTensor(test_x)\n",
        "train_y = torch.FloatTensor(train_y).view(-1)\n",
        "test_y = torch.FloatTensor(test_y).view(-1)\n",
        "\n",
        "# 建立 TensorDataset 和 DataLoader\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "test_dataset = TensorDataset(test_x, test_y)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "xmg-FQUlFHR_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義 LSTM 模型\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size = 10, hidden_size = 64, num_layers=1, batch_first= True)\n",
        "        self.Relu1 = nn.ReLU()\n",
        "        self.lstm2 = nn.LSTM(input_size =64, hidden_size =32, num_layers=1, batch_first=True)\n",
        "        self.Relu2 = nn.ReLU()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features = 32 , out_features = 64),\n",
        "            nn.Linear(in_features = 64, out_features = 32),\n",
        "            nn.Linear(in_features = 32, out_features =1),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out    = self.Relu1(out)\n",
        "\n",
        "        out, _ = self.lstm2(out)\n",
        "        out    = self.Relu2(out)\n",
        "\n",
        "        out = out[:, -1, :]  # 最後一個時間步\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "o-SJu2RnFNup"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# 初始化模型\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LSTMModel().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "# 訓練和驗證\n",
        "print(\"開始訓練\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        outputs = model(batch_x)\n",
        "        outputs = outputs.squeeze(-1)\n",
        "        loss = loss_func(outputs, batch_y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            outputs = outputs.squeeze(-1)\n",
        "            loss = loss_func(outputs, batch_y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "\n",
        "## 儲存模型\n",
        "torch.save(model,'LSTM_model_test1.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdWJnFlAFaD9",
        "outputId": "bdd761c5-247d-4367-b486-c79ef9a4e507"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "開始訓練\n",
            "Epoch [1/100], Train Loss: 0.6931, Val Loss: 0.6928\n",
            "Epoch [2/100], Train Loss: 0.6924, Val Loss: 0.6928\n",
            "Epoch [3/100], Train Loss: 0.6930, Val Loss: 0.6931\n",
            "Epoch [4/100], Train Loss: 0.6927, Val Loss: 0.6928\n",
            "Epoch [5/100], Train Loss: 0.6926, Val Loss: 0.6928\n",
            "Epoch [6/100], Train Loss: 0.6925, Val Loss: 0.6928\n",
            "Epoch [7/100], Train Loss: 0.6929, Val Loss: 0.6928\n",
            "Epoch [8/100], Train Loss: 0.6925, Val Loss: 0.6928\n",
            "Epoch [9/100], Train Loss: 0.6927, Val Loss: 0.6928\n",
            "Epoch [10/100], Train Loss: 0.6925, Val Loss: 0.6929\n",
            "Epoch [11/100], Train Loss: 0.6927, Val Loss: 0.6928\n",
            "Epoch [12/100], Train Loss: 0.6925, Val Loss: 0.6928\n",
            "Epoch [13/100], Train Loss: 0.6928, Val Loss: 0.6929\n",
            "Epoch [14/100], Train Loss: 0.6928, Val Loss: 0.6931\n",
            "Epoch [15/100], Train Loss: 0.6926, Val Loss: 0.6928\n",
            "Epoch [16/100], Train Loss: 0.6925, Val Loss: 0.6928\n",
            "Epoch [17/100], Train Loss: 0.6927, Val Loss: 0.6928\n",
            "Epoch [18/100], Train Loss: 0.6923, Val Loss: 0.6929\n",
            "Epoch [19/100], Train Loss: 0.6926, Val Loss: 0.6931\n",
            "Epoch [20/100], Train Loss: 0.6929, Val Loss: 0.6928\n",
            "Epoch [21/100], Train Loss: 0.6925, Val Loss: 0.6928\n",
            "Epoch [22/100], Train Loss: 0.6927, Val Loss: 0.6929\n",
            "Epoch [23/100], Train Loss: 0.6926, Val Loss: 0.6928\n",
            "Epoch [24/100], Train Loss: 0.6924, Val Loss: 0.6928\n",
            "Epoch [25/100], Train Loss: 0.6924, Val Loss: 0.6928\n",
            "Epoch [26/100], Train Loss: 0.6934, Val Loss: 0.6933\n",
            "Epoch [27/100], Train Loss: 0.6926, Val Loss: 0.6929\n",
            "Epoch [28/100], Train Loss: 0.6922, Val Loss: 0.6928\n",
            "Epoch [29/100], Train Loss: 0.6926, Val Loss: 0.6930\n",
            "Epoch [30/100], Train Loss: 0.6923, Val Loss: 0.6928\n",
            "Epoch [31/100], Train Loss: 0.6921, Val Loss: 0.6928\n",
            "Epoch [32/100], Train Loss: 0.6923, Val Loss: 0.6928\n",
            "Epoch [33/100], Train Loss: 0.6920, Val Loss: 0.6929\n",
            "Epoch [34/100], Train Loss: 0.6926, Val Loss: 0.6930\n",
            "Epoch [35/100], Train Loss: 0.6918, Val Loss: 0.6928\n",
            "Epoch [36/100], Train Loss: 0.6918, Val Loss: 0.6928\n",
            "Epoch [37/100], Train Loss: 0.6923, Val Loss: 0.6928\n",
            "Epoch [38/100], Train Loss: 0.6916, Val Loss: 0.6929\n",
            "Epoch [39/100], Train Loss: 0.6917, Val Loss: 0.6930\n",
            "Epoch [40/100], Train Loss: 0.6920, Val Loss: 0.6928\n",
            "Epoch [41/100], Train Loss: 0.6915, Val Loss: 0.6928\n",
            "Epoch [42/100], Train Loss: 0.6913, Val Loss: 0.6931\n",
            "Epoch [43/100], Train Loss: 0.6917, Val Loss: 0.6928\n",
            "Epoch [44/100], Train Loss: 0.6913, Val Loss: 0.6930\n",
            "Epoch [45/100], Train Loss: 0.6911, Val Loss: 0.6928\n",
            "Epoch [46/100], Train Loss: 0.6912, Val Loss: 0.6928\n",
            "Epoch [47/100], Train Loss: 0.6931, Val Loss: 0.6932\n",
            "Epoch [48/100], Train Loss: 0.6933, Val Loss: 0.6928\n",
            "Epoch [49/100], Train Loss: 0.6911, Val Loss: 0.6928\n",
            "Epoch [50/100], Train Loss: 0.6912, Val Loss: 0.6929\n",
            "Epoch [51/100], Train Loss: 0.6912, Val Loss: 0.6928\n",
            "Epoch [52/100], Train Loss: 0.6910, Val Loss: 0.6928\n",
            "Epoch [53/100], Train Loss: 0.6910, Val Loss: 0.6930\n",
            "Epoch [54/100], Train Loss: 0.6911, Val Loss: 0.6928\n",
            "Epoch [55/100], Train Loss: 0.6907, Val Loss: 0.6928\n",
            "Epoch [56/100], Train Loss: 0.6908, Val Loss: 0.6928\n",
            "Epoch [57/100], Train Loss: 0.6907, Val Loss: 0.6928\n",
            "Epoch [58/100], Train Loss: 0.6906, Val Loss: 0.6935\n",
            "Epoch [59/100], Train Loss: 0.6908, Val Loss: 0.6928\n",
            "Epoch [60/100], Train Loss: 0.6904, Val Loss: 0.6928\n",
            "Epoch [61/100], Train Loss: 0.6902, Val Loss: 0.6928\n",
            "Epoch [62/100], Train Loss: 0.6905, Val Loss: 0.6932\n",
            "Epoch [63/100], Train Loss: 0.6898, Val Loss: 0.6929\n",
            "Epoch [64/100], Train Loss: 0.6901, Val Loss: 0.6928\n",
            "Epoch [65/100], Train Loss: 0.6894, Val Loss: 0.6950\n",
            "Epoch [66/100], Train Loss: 0.6914, Val Loss: 0.6965\n",
            "Epoch [67/100], Train Loss: 0.6908, Val Loss: 0.6928\n",
            "Epoch [68/100], Train Loss: 0.6899, Val Loss: 0.6929\n",
            "Epoch [69/100], Train Loss: 0.6898, Val Loss: 0.6931\n",
            "Epoch [70/100], Train Loss: 0.6892, Val Loss: 0.6928\n",
            "Epoch [71/100], Train Loss: 0.6896, Val Loss: 0.6929\n",
            "Epoch [72/100], Train Loss: 0.6887, Val Loss: 0.6930\n",
            "Epoch [73/100], Train Loss: 0.6890, Val Loss: 0.6930\n",
            "Epoch [74/100], Train Loss: 0.6885, Val Loss: 0.6928\n",
            "Epoch [75/100], Train Loss: 0.6887, Val Loss: 0.6928\n",
            "Epoch [76/100], Train Loss: 0.6901, Val Loss: 0.6928\n",
            "Epoch [77/100], Train Loss: 0.6884, Val Loss: 0.6934\n",
            "Epoch [78/100], Train Loss: 0.6890, Val Loss: 0.6928\n",
            "Epoch [79/100], Train Loss: 0.6889, Val Loss: 0.6928\n",
            "Epoch [80/100], Train Loss: 0.6893, Val Loss: 0.6928\n",
            "Epoch [81/100], Train Loss: 0.6877, Val Loss: 0.6931\n",
            "Epoch [82/100], Train Loss: 0.6878, Val Loss: 0.6928\n",
            "Epoch [83/100], Train Loss: 0.6874, Val Loss: 0.6929\n",
            "Epoch [84/100], Train Loss: 0.6874, Val Loss: 0.6929\n",
            "Epoch [85/100], Train Loss: 0.6867, Val Loss: 0.6928\n",
            "Epoch [86/100], Train Loss: 0.6875, Val Loss: 0.6928\n",
            "Epoch [87/100], Train Loss: 0.6871, Val Loss: 0.6929\n",
            "Epoch [88/100], Train Loss: 0.6872, Val Loss: 0.6928\n",
            "Epoch [89/100], Train Loss: 0.6890, Val Loss: 0.6928\n",
            "Epoch [90/100], Train Loss: 0.6875, Val Loss: 0.6928\n",
            "Epoch [91/100], Train Loss: 0.6865, Val Loss: 0.6929\n",
            "Epoch [92/100], Train Loss: 0.6864, Val Loss: 0.6929\n",
            "Epoch [93/100], Train Loss: 0.6860, Val Loss: 0.6929\n",
            "Epoch [94/100], Train Loss: 0.6861, Val Loss: 0.6930\n",
            "Epoch [95/100], Train Loss: 0.6869, Val Loss: 0.6929\n",
            "Epoch [96/100], Train Loss: 0.6852, Val Loss: 0.6928\n",
            "Epoch [97/100], Train Loss: 0.6852, Val Loss: 0.6929\n",
            "Epoch [98/100], Train Loss: 0.6859, Val Loss: 0.6928\n",
            "Epoch [99/100], Train Loss: 0.6861, Val Loss: 0.6928\n",
            "Epoch [100/100], Train Loss: 0.6853, Val Loss: 0.6944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試集結果評估\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_preds = []\n",
        "    for batch_x, _ in test_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        outputs = model(batch_x)\n",
        "        #print(outputs.squeeze(-1).cpu().numpy())\n",
        "        test_preds.extend((outputs.squeeze(-1) > 0.5).cpu().numpy())\n",
        "\n",
        "test_preds = np.array(test_preds)\n",
        "accuracy = (test_preds == test_y.numpy()).mean()\n",
        "print(f\"測試集準確率: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbFyvCzmFUqL",
        "outputId": "1bf6ad8c-d264-4f80-8120-b4a2b9681fa0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "測試集準確率: 49.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#測試集結果評估 2\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for batch_x, labels in test_loader:\n",
        "        batch_x, labels = batch_x.to(device), labels.to(device) # 將 images 和 labels 轉移至 GPU\n",
        "        outputs = model(batch_x)\n",
        "        outputs = outputs.squeeze(-1)\n",
        "\n",
        "        ##算準確率\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.float()).sum().item()\n",
        "\n",
        "        #print(predicted, labels)\n",
        "\n",
        "accuracy_on_testData =  correct / total * 100\n",
        "print(f'Accuracy on test data: {accuracy_on_testData:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib9TtBEyFxr5",
        "outputId": "fc05786b-4917-424d-d352-96d17d8ffb8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 49.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fS5ogD81F0UN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.使用LSTM與CNN進行特徵層融合"
      ],
      "metadata": {
        "id": "1cgaHroAF5QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands"
      ],
      "metadata": {
        "id": "iTWDx5nvGsP2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_id = '3711.TW'\n",
        "\n",
        "#抓取特定時間\n",
        "start = dt.datetime(2020,1,1)\n",
        "end   = dt.datetime(2024, 10,10 )\n",
        "data = yf.download(stock_id, start= start, end=end)\n",
        "\n",
        "data = data.reset_index()\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Date'] = data['Date'].dt.strftime('%Y_%m_%d')\n",
        "\n",
        "data = data.droplevel('Ticker', axis=1) # 刪除 `Ticker` 這層索引\n",
        "data =data.drop(columns=['Adj Close'])  # 這是需要寫等於的。\n",
        "\n",
        "\n",
        "# 加入目標變數 (Diff)\n",
        "data['Next_close'] = data['Close'].shift(-1)\n",
        "data['Diff'] = (data['Next_close'] > data['Close']).astype('int')\n",
        "data = data.dropna()  # 確保沒有 NaN 資料\n",
        "\n",
        "# 加入技術指標\n",
        "data['SMA_5'] = data['Close'].rolling(window=5).mean()\n",
        "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
        "\n",
        "rsi = RSIIndicator(close=data['Close'], window=14)\n",
        "data['RSI_14'] = rsi.rsi()\n",
        "\n",
        "macd = MACD(close=data['Close'])\n",
        "data['MACD'] = macd.macd()\n",
        "data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "bb = BollingerBands(close=data['Close'], window=20, window_dev=2)\n",
        "data['BB_upper'] = bb.bollinger_hband()\n",
        "data['BB_lower'] = bb.bollinger_lband()\n",
        "data['BB_width'] = data['BB_upper'] - data['BB_lower']\n",
        "\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn1mdfcdG89K",
        "outputId": "e3c0d8b8-e5f7-41fd-fb02-dcfd12882bed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 準備劃K線圖的資料。\n",
        "twenty_days = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(data.values) -20):\n",
        "    #segment = data[['Open','High','Low','Close']].values[i:i+20]\n",
        "    segment = data[['Open', 'High', 'Low', 'Close', 'Volume',\n",
        "                    'SMA_5', 'SMA_20', 'RSI_14', 'MACD', 'BB_width']].values[i:i + 20]\n",
        "\n",
        "    twenty_days.append(segment)\n",
        "    labels.append(data['Diff'].values[i+19]) #他要是到19 就有答案了。\n"
      ],
      "metadata": {
        "id": "qLtOR3d8HGsB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割訓練和測試集\n",
        "train_size = int(len(labels) * 0.8)\n",
        "train_x = np.array(twenty_days[:train_size], dtype=np.float32)\n",
        "test_x = np.array(twenty_days[train_size:], dtype=np.float32)\n",
        "\n",
        "train_y = np.array(labels[:train_size], dtype=np.float32)  ## 這裡是有時間的， 沒辦法直接這樣轉。\n",
        "test_y = np.array(labels[train_size:], dtype=np.float32)\n",
        "\n",
        "\n",
        "# 先處理 train_x\n",
        "train_rise_folder = './CNN_LSTM_data/train_folder_path/rise'\n",
        "train_fail_folder = './CNN_LSTM_data/train_folder_path/fail'\n",
        "test_rise_folder = './CNN_LSTM_data/test_folder_path/rise'\n",
        "test_fail_folder = './CNN_LSTM_data/test_folder_path/fail'\n"
      ],
      "metadata": {
        "id": "Om5f2ByvHI8T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rise_folder = './CNN_LSTM_data/train_folder_path/rise'\n",
        "train_fail_folder = './CNN_LSTM_data/train_folder_path/fail'\n",
        "test_rise_folder = './CNN_LSTM_data/test_folder_path/rise'\n",
        "test_fail_folder = './CNN_LSTM_data/test_folder_path/fail'\n",
        "\n",
        "for folder in [train_rise_folder, train_fail_folder, test_rise_folder, test_fail_folder]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "for idx, segment in enumerate(train_x):\n",
        "    #plt.figure(figsize=(1,1))\n",
        "    # 創建圖像\n",
        "    fig, ax = plt.subplots() # 設置圖像大小（英寸）和 DPI\n",
        "    fig.set_size_inches(0.5, 0.5)\n",
        "    for day_idx ,day in enumerate(segment):\n",
        "\n",
        "        Open_price, high_price , low_price, Close_price = map(int, day[0:4])\n",
        "        color = \"red\" if Close_price > Open_price else \"green\"\n",
        "\n",
        "        plt.bar(day_idx, abs(Close_price - Open_price), bottom=min(Open_price, Close_price), color=color, width=0.5)\n",
        "        plt.bar(day_idx, high_price - low_price, bottom=low_price,color=color, width=0.1 )\n",
        "\n",
        "    rise_or_fall = \"rise\" if train_y[idx] ==1 else \"fail\"\n",
        "    plt.axis('off')\n",
        "    if rise_or_fall == 'rise':\n",
        "        plt.savefig(f'{train_rise_folder}/{idx:05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    else:\n",
        "        plt.savefig(f'{train_fail_folder}/{idx:05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "KoUIBe17HNPQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, segment in enumerate(test_x):\n",
        "    fig, ax = plt.subplots() # 設置圖像大小（英寸）和 DPI\n",
        "    fig.set_size_inches(0.5, 0.5)\n",
        "    for day_idx ,day in enumerate(segment):\n",
        "        Open_price, high_price , low_price, Close_price = map(int, day[0:4])\n",
        "        color = \"red\" if Close_price > Open_price else \"green\"\n",
        "\n",
        "        plt.bar(day_idx, abs(Close_price - Open_price), bottom=min(Open_price, Close_price), color=color, width=0.5)\n",
        "        plt.bar(day_idx, high_price - low_price, bottom=low_price,color=color, width=0.1 )\n",
        "\n",
        "    rise_or_fall = \"rise\" if test_y[idx] ==1 else \"fail\"\n",
        "    plt.axis('off')\n",
        "    if rise_or_fall == 'rise':\n",
        "        plt.savefig(f'{test_rise_folder}/{(len(train_x)+idx):05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    else:\n",
        "        plt.savefig(f'{test_fail_folder}/{(len(train_x)+idx):05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "UxYFS5NvHXOR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "# Dataset and DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((50, 50)),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "class FusionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, lstm_data, lstm_labels, image_folder, transform=None):\n",
        "        self.lstm_data = lstm_data\n",
        "        self.lstm_labels = lstm_labels\n",
        "        self.image_data = datasets.ImageFolder(root=image_folder, transform= transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lstm_data)\n",
        "\n",
        "    def __getitem__(self, idx):   ## 多思，如果他這樣寫，是什麼時候會需要被呼叫使用。\n",
        "        lstm_data = self.lstm_data[idx]\n",
        "        lstm_label = self.lstm_labels[idx]\n",
        "        cnn_image, cnn_label = self.image_data[idx]\n",
        "        return torch.FloatTensor(lstm_data), cnn_image, lstm_label\n",
        "\n",
        "CNN_train_path = './CNN_LSTM_data/train_folder_path/'\n",
        "CNN_test_path  = './CNN_LSTM_data/test_folder_path/'\n",
        "train_dataset = FusionDataset(lstm_data = train_x, lstm_labels = train_y, image_folder = CNN_train_path, transform= transform)\n",
        "test_dataset = FusionDataset(lstm_data = test_x, lstm_labels = test_y, image_folder = CNN_test_path, transform= transform)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle = True)\n",
        "test_loader  = DataLoader(test_dataset , batch_size=16, shuffle= False)\n"
      ],
      "metadata": {
        "id": "bUuKEy-GKc9U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% # 定義模型。 Fusion Model Definition\n",
        "import torch.nn as nn\n",
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, lstm_input_size, cnn_input_shape):  ##多思， 它這裡只是先做定義而已。\n",
        "        super(FusionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size = lstm_input_size, hidden_size = 64, num_layers=2 , batch_first=True)\n",
        "        self.lstm_fc = nn.Linear(in_features = 64, out_features = 32)\n",
        "\n",
        "        self.cnn = nn.Sequential(   ## 多思， 他這邊就用 Sequential 去做。  #自己要知道 Sequential 是要有逗號的。\n",
        "            nn.Conv2d(in_channels= 3 , out_channels=32, kernel_size=3, stride=1, padding=0),    #(50* 50)  -> (48 * 48)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), ## (48, 48) -> (24,24)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 32, out_channels = 48, kernel_size = 3, stride=1, padding=0), #(24, 24) -> (22, 22)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) , # (22, 22)  -> (11, 11)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 48, out_channels = 64, kernel_size = 3, stride=1, padding=0),  ## (11,11) -> (9, 9)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  #(9,9)  => (4,4)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels = 64, out_channels = 96, kernel_size = 3, stride=1, padding=0), ## (4*4 ) -> (2* 2)\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # (2* 2) -> (1* 1)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            )\n",
        "        self.FusionPart = nn.Sequential(\n",
        "            nn.Linear(in_features = 32 + 96 , out_features = 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = 256 , out_features =32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features= 32, out_features = 1),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def  forward(self, time_data, image_data):\n",
        "        lstm_out, _ = self.lstm(time_data)\n",
        "        lstm_feature = self.lstm_fc(lstm_out[:,-1, :]) #32\n",
        "\n",
        "        cnn_out = self.cnn(image_data)\n",
        "        cnn_out = cnn_out.view(cnn_out.size(0), -1) ##我要把它做攤平。 96\n",
        "\n",
        "        fused_feature = torch.cat((lstm_feature, cnn_out), dim=1)\n",
        "        fused_feature = self.FusionPart(fused_feature)\n",
        "\n",
        "        return fused_feature\n"
      ],
      "metadata": {
        "id": "BuvQcMmDIsSj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%  ## 我要去做訓練的動作了。\n",
        "import torch.optim as optim\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FusionModel(lstm_input_size = 10 , cnn_input_shape =(3, 50, 50) ).to(device)\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0  ##多思， 他這樣也有要計算correct 的想法。\n",
        "\n",
        "    for lstm_data, cnn_data, labels in train_loader: #多思，我們看這個， 它是可以一次全部的喔!!， 讚讚。\n",
        "        lstm_data, cnn_data, labels = lstm_data.to(device), cnn_data.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(lstm_data, cnn_data)\n",
        "        output = output.squeeze(-1)\n",
        "        loss  = loss_func(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()    ## 多思， 這個loss 要去除嗎? 它怎麼沒有這樣去做???\n",
        "        predicted = (output > 0.5).float()  ## 多思，這是要去做它輸出的結果。\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)  ## 多思， 這算總和的方式是這樣去算的。\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYBEGkCXKjMY",
        "outputId": "b2d7678e-cbc2-4a4b-f2af-f4a7cb5d3505"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.6932, Accuracy: 0.5187\n",
            "Epoch [2/50], Loss: 0.6927, Accuracy: 0.5187\n",
            "Epoch [3/50], Loss: 0.6927, Accuracy: 0.5187\n",
            "Epoch [4/50], Loss: 0.6933, Accuracy: 0.5187\n",
            "Epoch [5/50], Loss: 0.6932, Accuracy: 0.5187\n",
            "Epoch [6/50], Loss: 0.6927, Accuracy: 0.5187\n",
            "Epoch [7/50], Loss: 0.6931, Accuracy: 0.5187\n",
            "Epoch [8/50], Loss: 0.6931, Accuracy: 0.5187\n",
            "Epoch [9/50], Loss: 0.6924, Accuracy: 0.5187\n",
            "Epoch [10/50], Loss: 0.6929, Accuracy: 0.5187\n",
            "Epoch [11/50], Loss: 0.6929, Accuracy: 0.5187\n",
            "Epoch [12/50], Loss: 0.6927, Accuracy: 0.5187\n",
            "Epoch [13/50], Loss: 0.6923, Accuracy: 0.5187\n",
            "Epoch [14/50], Loss: 0.6924, Accuracy: 0.5187\n",
            "Epoch [15/50], Loss: 0.6913, Accuracy: 0.5187\n",
            "Epoch [16/50], Loss: 0.6914, Accuracy: 0.5187\n",
            "Epoch [17/50], Loss: 0.6916, Accuracy: 0.5187\n",
            "Epoch [18/50], Loss: 0.6915, Accuracy: 0.5187\n",
            "Epoch [19/50], Loss: 0.6915, Accuracy: 0.5187\n",
            "Epoch [20/50], Loss: 0.6913, Accuracy: 0.5187\n",
            "Epoch [21/50], Loss: 0.6910, Accuracy: 0.5187\n",
            "Epoch [22/50], Loss: 0.6914, Accuracy: 0.5187\n",
            "Epoch [23/50], Loss: 0.6908, Accuracy: 0.5187\n",
            "Epoch [24/50], Loss: 0.6905, Accuracy: 0.5187\n",
            "Epoch [25/50], Loss: 0.6913, Accuracy: 0.5187\n",
            "Epoch [26/50], Loss: 0.6909, Accuracy: 0.5187\n",
            "Epoch [27/50], Loss: 0.6917, Accuracy: 0.5187\n",
            "Epoch [28/50], Loss: 0.6921, Accuracy: 0.4972\n",
            "Epoch [29/50], Loss: 0.6911, Accuracy: 0.5187\n",
            "Epoch [30/50], Loss: 0.6916, Accuracy: 0.5187\n",
            "Epoch [31/50], Loss: 0.6909, Accuracy: 0.5187\n",
            "Epoch [32/50], Loss: 0.6911, Accuracy: 0.5198\n",
            "Epoch [33/50], Loss: 0.6916, Accuracy: 0.5187\n",
            "Epoch [34/50], Loss: 0.6911, Accuracy: 0.5198\n",
            "Epoch [35/50], Loss: 0.6965, Accuracy: 0.5119\n",
            "Epoch [36/50], Loss: 0.6918, Accuracy: 0.5187\n",
            "Epoch [37/50], Loss: 0.6910, Accuracy: 0.5198\n",
            "Epoch [38/50], Loss: 0.6884, Accuracy: 0.5198\n",
            "Epoch [39/50], Loss: 0.6908, Accuracy: 0.5198\n",
            "Epoch [40/50], Loss: 0.6907, Accuracy: 0.5198\n",
            "Epoch [41/50], Loss: 0.6902, Accuracy: 0.5255\n",
            "Epoch [42/50], Loss: 0.6867, Accuracy: 0.5300\n",
            "Epoch [43/50], Loss: 0.6835, Accuracy: 0.5413\n",
            "Epoch [44/50], Loss: 0.6860, Accuracy: 0.5402\n",
            "Epoch [45/50], Loss: 0.6858, Accuracy: 0.5425\n",
            "Epoch [46/50], Loss: 0.6803, Accuracy: 0.5459\n",
            "Epoch [47/50], Loss: 0.6815, Accuracy: 0.5481\n",
            "Epoch [48/50], Loss: 0.6782, Accuracy: 0.5561\n",
            "Epoch [49/50], Loss: 0.6742, Accuracy: 0.5595\n",
            "Epoch [50/50], Loss: 0.6699, Accuracy: 0.5606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%   ## 進行評估。\n",
        "\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for lstm_data, cnn_data, labels in test_loader:\n",
        "        lstm_data, cnn_data, labels = lstm_data.to(device), cnn_data.to(device), labels.to(device)\n",
        "\n",
        "        output = model(lstm_data, cnn_data)\n",
        "        output = output.squeeze(-1)\n",
        "        predicted = (output > 0.5).float()\n",
        "\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_accuracy = correct /total\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yrGiFauKnDb",
        "outputId": "093fc18a-8678-4ecd-a3f2-cd0f04508a9a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1fEWK5tLeXU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.CNN+LSTM 決策層融合"
      ],
      "metadata": {
        "id": "5PpSac5uQj1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands\n",
        "import datetime as dt"
      ],
      "metadata": {
        "id": "J6CvETxdQoTw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_id = '3711.TW'\n",
        "\n",
        "#抓取特定時間\n",
        "start = dt.datetime(2020,1,1)\n",
        "end   = dt.datetime(2024, 10,10 )\n",
        "data = yf.download(stock_id, start= start, end=end)\n",
        "\n",
        "data = data.reset_index()\n",
        "data['Date'] = pd.to_datetime(data['Date']) ## 讓她是時間間數據。\n",
        "data['Date'] = data['Date'].dt.strftime('%Y_%m_%d')\n",
        "\n",
        "data = data.droplevel('Ticker', axis=1) # 刪除 `Ticker` 這層索引\n",
        "data =data.drop(columns=['Adj Close'])  # 這是需要寫等於的。\n",
        "\n",
        "# 加入目標變數。\n",
        "data['Next_close'] = data['Close'].shift(-1) ## 將Close 欄位向上移動一行， 這樣'Next_Close' 會是下一天收盤價。\n",
        "data['Diff'] = (data['Next_close'] > data['Close']).astype('int') ## 比較 'Next_Close' 和 'Close'，大於為1 ， 小於為0。 1代表漲的意識， 0 代表跌的意識。\n",
        "#print(data.head(5))\n",
        "\n",
        "\n",
        "# 加入技術指標。\n",
        "data['SMA_5'] = data['Close'].rolling(window=5).mean()\n",
        "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
        "\n",
        "rsi = RSIIndicator(close=data['Close'], window=14)\n",
        "data['RSI_14'] = rsi.rsi()\n",
        "\n",
        "macd = MACD(close=data['Close'])\n",
        "data['MACD'] = macd.macd()\n",
        "data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "bb = BollingerBands(close=data['Close'], window=20, window_dev=2)\n",
        "data['BB_upper'] = bb.bollinger_hband()\n",
        "data['BB_lower'] = bb.bollinger_lband()\n",
        "data['BB_width'] = data['BB_upper'] - data['BB_lower']\n",
        "data = data.dropna()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR_t-BRXQqCj",
        "outputId": "b14914e5-1a11-41e9-ceff-b9fbc6c1cbd0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 準備劃K線圖的資料。\n",
        "twenty_days = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(data.values) -20):\n",
        "    #segment = data[['Open','High','Low','Close']].values[i:i+20]\n",
        "    segment = data[['Open', 'High', 'Low', 'Close', 'Volume',\n",
        "                    'SMA_5', 'SMA_20', 'RSI_14', 'MACD', 'BB_width']].values[i:i + 20]\n",
        "\n",
        "    twenty_days.append(segment)\n",
        "    labels.append(data['Diff'].values[i+19]) #他要是到19 就有答案了。"
      ],
      "metadata": {
        "id": "8pEdUlXQQtqH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割訓練和測試集\n",
        "train_size = int(len(labels) * 0.8)\n",
        "train_x = np.array(twenty_days[:train_size], dtype=np.float32)\n",
        "test_x = np.array(twenty_days[train_size:], dtype=np.float32)\n",
        "\n",
        "train_y = np.array(labels[:train_size], dtype=np.float32)  ## 這裡是有時間的， 沒辦法直接這樣轉。\n",
        "test_y = np.array(labels[train_size:], dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "K_cjLxdqQxdj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rise_folder = './late_CNN_LSTM_data/train_folder_path/rise'\n",
        "train_fail_folder = './late_CNN_LSTM_data/train_folder_path/fail'\n",
        "test_rise_folder = './late_CNN_LSTM_data/test_folder_path/rise'\n",
        "test_fail_folder = './late_CNN_LSTM_data/test_folder_path/fail'\n",
        "\n",
        "for folder in [train_rise_folder, train_fail_folder, test_rise_folder, test_fail_folder]:\n",
        "    os.makedirs(folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "EDXOHl3PQzcv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, segment in enumerate(train_x):\n",
        "    # 創建圖像\n",
        "    fig, ax = plt.subplots() # 設置圖像大小（英寸）和 DPI\n",
        "    fig.set_size_inches(0.5, 0.5)\n",
        "    for day_idx ,day in enumerate(segment):\n",
        "\n",
        "\n",
        "        Open_price, high_price , low_price, Close_price = map(int, day[0:4])\n",
        "        color = \"red\" if Close_price > Open_price else \"green\"\n",
        "\n",
        "        plt.bar(day_idx, abs(Close_price - Open_price), bottom=min(Open_price, Close_price), color=color, width=0.5)\n",
        "        plt.bar(day_idx, high_price - low_price, bottom=low_price,color=color, width=0.1 )\n",
        "\n",
        "    rise_or_fall = \"rise\" if train_y[idx] ==1 else \"fail\"\n",
        "    plt.axis('off')\n",
        "    if rise_or_fall == 'rise':\n",
        "        plt.savefig(f'{train_rise_folder}/{idx:05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    else:\n",
        "        plt.savefig(f'{train_fail_folder}/{idx:05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    plt.close()\n",
        ""
      ],
      "metadata": {
        "id": "EkCZH-h2Q2vq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, segment in enumerate(test_x):\n",
        "    fig, ax = plt.subplots() # 設置圖像大小（英寸）和 DPI\n",
        "    fig.set_size_inches(0.5, 0.5)\n",
        "    for day_idx ,day in enumerate(segment):\n",
        "        Open_price, high_price , low_price, Close_price = map(int, day[0:4])\n",
        "        color = \"red\" if Close_price > Open_price else \"green\"\n",
        "\n",
        "        plt.bar(day_idx, abs(Close_price - Open_price), bottom=min(Open_price, Close_price), color=color, width=0.5)\n",
        "        plt.bar(day_idx, high_price - low_price, bottom=low_price,color=color, width=0.1 )\n",
        "\n",
        "    rise_or_fall = \"rise\" if test_y[idx] ==1 else \"fail\"\n",
        "    plt.axis('off')\n",
        "    if rise_or_fall == 'rise':\n",
        "        plt.savefig(f'{test_rise_folder}/{(len(train_x)+idx):05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    else:\n",
        "        plt.savefig(f'{test_fail_folder}/{(len(train_x)+idx):05d}_{rise_or_fall}.png', format='png',dpi=100)  ## 儲存圖片\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "TPVfu8xLQ8oP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "# Dataset and DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((50, 50)),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "class FusionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, lstm_data, lstm_labels, image_folder, transform=None):\n",
        "        self.lstm_data = lstm_data\n",
        "        self.lstm_labels = lstm_labels\n",
        "        self.image_data = datasets.ImageFolder(root=image_folder, transform= transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lstm_data)\n",
        "\n",
        "    def __getitem__(self, idx):   ## 多思，如果他這樣寫，是什麼時候會需要被呼叫使用。\n",
        "        lstm_data = self.lstm_data[idx]\n",
        "        lstm_label = self.lstm_labels[idx]\n",
        "        cnn_image, cnn_label = self.image_data[idx]\n",
        "        return torch.FloatTensor(lstm_data), cnn_image, lstm_label\n",
        "\n",
        "CNN_train_path = './late_CNN_LSTM_data/train_folder_path/'\n",
        "CNN_test_path  = './late_CNN_LSTM_data/test_folder_path/'\n",
        "train_dataset = FusionDataset(lstm_data = train_x, lstm_labels = train_y, image_folder = CNN_train_path, transform= transform)\n",
        "test_dataset = FusionDataset(lstm_data = test_x, lstm_labels = test_y, image_folder = CNN_test_path, transform= transform)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle = True)\n",
        "test_loader  = DataLoader(test_dataset , batch_size=16, shuffle= False)\n"
      ],
      "metadata": {
        "id": "xDs5kcpTRYK7"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "ToNY2YhvSGaq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% 定義模型結構\n",
        "class MLP_FusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_FusionModel, self).__init__()\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features=2, out_features=16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=16, out_features=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4, out_features=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, LSTM_value, CNN_value):\n",
        "        fused_feature = torch.cat((LSTM_value, CNN_value), dim=1)\n",
        "        out = self.linear(fused_feature)\n",
        "        return out\n",
        "\n",
        "\n",
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Model, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, stride=1, padding=0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features=96, out_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=64, out_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=32, out_features=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        cnn_out = out.view(out.size(0), -1)  # 攤平處理\n",
        "        linear_out = self.linear(cnn_out)\n",
        "        return linear_out\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm1 = nn.LSTM(input_size=10, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=32, out_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=64, out_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=32, out_features=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.relu1(out)\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = out[:, -1, :]  # 取最後一個時間步\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "9VfUdYAHSGwg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% 設定設備與載入模型\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "CNN_model = CNN_Model().to(device)\n",
        "LSTM_model = LSTMModel().to(device)\n",
        "MLP_model = MLP_FusionModel().to(device)"
      ],
      "metadata": {
        "id": "aatPIXcoSGzV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% 設定訓練與驗證函數\n",
        "def train_epoch(train_loader, models, optimizer, loss_func, device):\n",
        "    CNN_model, LSTM_model, MLP_model = models\n",
        "    CNN_model.train()\n",
        "    LSTM_model.train()\n",
        "    MLP_model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for lstm_data, cnn_data, labels in train_loader:\n",
        "        lstm_data, cnn_data, labels = lstm_data.to(device), cnn_data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        lstm_value = LSTM_model(lstm_data)\n",
        "        cnn_value = CNN_model(cnn_data)\n",
        "        output = MLP_model(lstm_value, cnn_value).squeeze(-1)\n",
        "\n",
        "        loss = loss_func(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        predicted = (output > 0.5).float()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(train_loader), correct / total\n",
        "\n",
        "\n",
        "def evaluate(val_loader, models, loss_func, device):\n",
        "    CNN_model, LSTM_model, MLP_model = models\n",
        "    CNN_model.eval()\n",
        "    LSTM_model.eval()\n",
        "    MLP_model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for lstm_data, cnn_data, labels in val_loader:\n",
        "            lstm_data, cnn_data, labels = lstm_data.to(device), cnn_data.to(device), labels.to(device)\n",
        "            lstm_value = LSTM_model(lstm_data)\n",
        "            cnn_value = CNN_model(cnn_data)\n",
        "            output = MLP_model(lstm_value, cnn_value).squeeze(-1)\n",
        "\n",
        "            loss = loss_func(output, labels)\n",
        "            total_loss += loss.item()\n",
        "            predicted = (output > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(val_loader), correct / total"
      ],
      "metadata": {
        "id": "27zheRu5SWBk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% 訓練流程\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = optim.Adam(MLP_model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(train_loader, (CNN_model, LSTM_model, MLP_model), optimizer, loss_func, device)\n",
        "    val_loss, val_acc = evaluate(test_loader, (CNN_model, LSTM_model, MLP_model), loss_func, device)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61bLAuyGSWII",
        "outputId": "a246bf5b-cad1-4c01-da43-8ec44119f89a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50]\n",
            "Train Loss: 0.6932, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6965, Validation Accuracy: 0.5023\n",
            "Epoch [2/50]\n",
            "Train Loss: 0.6926, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6958, Validation Accuracy: 0.5023\n",
            "Epoch [3/50]\n",
            "Train Loss: 0.6937, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6953, Validation Accuracy: 0.5023\n",
            "Epoch [4/50]\n",
            "Train Loss: 0.6939, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6948, Validation Accuracy: 0.5023\n",
            "Epoch [5/50]\n",
            "Train Loss: 0.6932, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6943, Validation Accuracy: 0.5023\n",
            "Epoch [6/50]\n",
            "Train Loss: 0.6919, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6940, Validation Accuracy: 0.5023\n",
            "Epoch [7/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6940, Validation Accuracy: 0.5023\n",
            "Epoch [8/50]\n",
            "Train Loss: 0.6933, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6939, Validation Accuracy: 0.5023\n",
            "Epoch [9/50]\n",
            "Train Loss: 0.6927, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [10/50]\n",
            "Train Loss: 0.6925, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [11/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [12/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [13/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [14/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [15/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [16/50]\n",
            "Train Loss: 0.6927, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [17/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [18/50]\n",
            "Train Loss: 0.6920, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [19/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6939, Validation Accuracy: 0.5023\n",
            "Epoch [20/50]\n",
            "Train Loss: 0.6925, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [21/50]\n",
            "Train Loss: 0.6930, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6940, Validation Accuracy: 0.5023\n",
            "Epoch [22/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [23/50]\n",
            "Train Loss: 0.6925, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [24/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [25/50]\n",
            "Train Loss: 0.6921, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [26/50]\n",
            "Train Loss: 0.6933, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [27/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [28/50]\n",
            "Train Loss: 0.6932, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [29/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6935, Validation Accuracy: 0.5023\n",
            "Epoch [30/50]\n",
            "Train Loss: 0.6927, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6935, Validation Accuracy: 0.5023\n",
            "Epoch [31/50]\n",
            "Train Loss: 0.6921, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6935, Validation Accuracy: 0.5023\n",
            "Epoch [32/50]\n",
            "Train Loss: 0.6925, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [33/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [34/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [35/50]\n",
            "Train Loss: 0.6921, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [36/50]\n",
            "Train Loss: 0.6920, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [37/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6939, Validation Accuracy: 0.5023\n",
            "Epoch [38/50]\n",
            "Train Loss: 0.6923, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6939, Validation Accuracy: 0.5023\n",
            "Epoch [39/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [40/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [41/50]\n",
            "Train Loss: 0.6925, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [42/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [43/50]\n",
            "Train Loss: 0.6924, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [44/50]\n",
            "Train Loss: 0.6931, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6937, Validation Accuracy: 0.5023\n",
            "Epoch [45/50]\n",
            "Train Loss: 0.6922, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6935, Validation Accuracy: 0.5023\n",
            "Epoch [46/50]\n",
            "Train Loss: 0.6919, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6938, Validation Accuracy: 0.5023\n",
            "Epoch [47/50]\n",
            "Train Loss: 0.6933, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6939, Validation Accuracy: 0.5023\n",
            "Epoch [48/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [49/50]\n",
            "Train Loss: 0.6928, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n",
            "Epoch [50/50]\n",
            "Train Loss: 0.6931, Train Accuracy: 0.5187\n",
            "Validation Loss: 0.6936, Validation Accuracy: 0.5023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sOh3p6FSc96"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}
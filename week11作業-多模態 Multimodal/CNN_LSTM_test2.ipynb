{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uw5wcXTn14kR"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stock Data Preparation"
      ],
      "metadata": {
        "id": "Q9tW_j1qT-RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "taiwan_2330_stock = yf.Ticker(\"2330.TW\")\n",
        "data = taiwan_2330_stock.history(period=\"5y\")\n",
        "\n",
        "if data.empty:\n",
        "    raise ValueError(\"Stock data is empty. Please check the ticker symbol or network connection.\")\n",
        "\n",
        "K_data = data[['Open', 'Close', 'High', 'Low']]\n",
        "ten_data = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(K_data.values) - 19):\n",
        "    segment = K_data.values[i:i+20]\n",
        "    ten_data.append(segment)\n",
        "\n",
        "    if i < len(K_data.values) - 20:\n",
        "        next_segment = K_data.values[i+1:i+21]\n",
        "        next_close_prices = [day[1] for day in next_segment]  # Extract close prices\n",
        "        MA20 = sum(next_close_prices) / len(next_close_prices)\n",
        "        MA10 = sum(next_close_prices[-10:]) / len(next_close_prices[-10:])\n",
        "        labels.append(1 if MA10 > MA20 else 0)\n"
      ],
      "metadata": {
        "id": "TLlB9iTj2B3_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Line Chart Generation"
      ],
      "metadata": {
        "id": "5odWNRSkUFX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = './image'\n",
        "os.makedirs(image_path, exist_ok=True)\n",
        "\n",
        "for idx, segment in enumerate(ten_data[:-1]):\n",
        "    for day_idx, day in enumerate(segment):\n",
        "        open_price, close_price, high_price, low_price = map(int, day)\n",
        "        color = \"red\" if close_price > open_price else \"green\"\n",
        "\n",
        "        plt.bar(day_idx, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.5)\n",
        "        plt.bar(day_idx, high_price - low_price, bottom=low_price, color=color, width=0.1)\n",
        "\n",
        "    rise_or_fall = \"rise\" if labels[idx] == 1 else \"fail\"\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f'{image_path}/{idx:05d}_{rise_or_fall}.png', format='png', dpi=100)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "ZfErp76h2Dxj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation"
      ],
      "metadata": {
        "id": "IRF6fkmEUJ1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Dataset Preparation\n",
        "train_rise_folder = './train_folder_path/rise'\n",
        "train_fail_folder = './train_folder_path/fail'\n",
        "test_rise_folder = './test_folder_path/rise'\n",
        "test_fail_folder = './test_folder_path/fail'\n",
        "\n",
        "for folder in [train_rise_folder, train_fail_folder, test_rise_folder, test_fail_folder]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "image_files = os.listdir(image_path)\n",
        "X_train, X_test, y_train, y_test = train_test_split(ten_data[:-1], labels, test_size=0.2, random_state=42)\n",
        "image_train, image_test = train_test_split(image_files, test_size=0.2, random_state=42)\n",
        "\n",
        "for img in image_train:\n",
        "    src = os.path.join(image_path, img)\n",
        "    dest = os.path.join(train_rise_folder if 'rise' in img else train_fail_folder, img)\n",
        "    shutil.copy(src, dest)\n",
        "\n",
        "for img in image_test:\n",
        "    src = os.path.join(image_path, img)\n",
        "    dest = os.path.join(test_rise_folder if 'rise' in img else test_fail_folder, img)\n",
        "    shutil.copy(src, dest)\n"
      ],
      "metadata": {
        "id": "-tzNC62E2FlA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fusion Model Definition"
      ],
      "metadata": {
        "id": "zeGPzn4bUOsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, lstm_input_size, cnn_input_shape):\n",
        "        super(FusionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=64, num_layers=2, batch_first=True)\n",
        "        self.lstm_fc = nn.Linear(64, 128)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        cnn_height, cnn_width = cnn_input_shape[1] // 4, cnn_input_shape[2] // 4\n",
        "        self.cnn_fc = nn.Linear(32 * cnn_height * cnn_width, 128)\n",
        "        self.fusion_fc = nn.Linear(128 + 128, 2)\n",
        "\n",
        "    def forward(self, time_data, image_data):\n",
        "        lstm_out, _ = self.lstm(time_data)\n",
        "        lstm_features = self.lstm_fc(lstm_out[:, -1, :])\n",
        "        cnn_out = self.cnn(image_data)\n",
        "        cnn_features = self.cnn_fc(cnn_out.view(cnn_out.size(0), -1))\n",
        "        fused_features = torch.cat((lstm_features, cnn_features), dim=1)\n",
        "        return self.fusion_fc(fused_features)\n"
      ],
      "metadata": {
        "id": "fJNlAhUO2H90"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Dataset and DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class FusionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, lstm_data, lstm_labels, image_folder, transform=None):\n",
        "        self.lstm_data = lstm_data\n",
        "        self.lstm_labels = lstm_labels\n",
        "        self.image_data = datasets.ImageFolder(root=image_folder, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lstm_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lstm_data = self.lstm_data[idx]\n",
        "        lstm_label = self.lstm_labels[idx]\n",
        "        cnn_image, cnn_label = self.image_data[idx]\n",
        "        return torch.FloatTensor(lstm_data), cnn_image, lstm_label\n",
        "\n",
        "train_dataset = FusionDataset(X_train, y_train, 'train_folder_path/', transform=transform)\n",
        "test_dataset = FusionDataset(X_test, y_test, 'test_folder_path/', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "7krr_4mU2KGE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Training Loop"
      ],
      "metadata": {
        "id": "-vMK_R2WUVbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FusionModel(lstm_input_size=4, cnn_input_shape=(3, 128, 128)).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for lstm_data, cnn_data, labels in train_loader:\n",
        "        lstm_data, cnn_data, labels = lstm_data.to(device), cnn_data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(lstm_data, cnn_data)\n",
        "        loss = loss_func(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch + 1}/10], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPw0bh-C2M2p",
        "outputId": "92373fdc-c2fc-432c-b795-aacce955c882"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 54.7348, Accuracy: 0.5617\n",
            "Epoch [2/10], Loss: 40.9926, Accuracy: 0.5785\n",
            "Epoch [3/10], Loss: 40.9409, Accuracy: 0.5785\n",
            "Epoch [4/10], Loss: 40.9128, Accuracy: 0.5785\n",
            "Epoch [5/10], Loss: 40.9307, Accuracy: 0.5785\n",
            "Epoch [6/10], Loss: 40.9222, Accuracy: 0.5785\n",
            "Epoch [7/10], Loss: 40.9126, Accuracy: 0.5785\n",
            "Epoch [8/10], Loss: 40.9815, Accuracy: 0.5785\n",
            "Epoch [9/10], Loss: 40.8697, Accuracy: 0.5785\n",
            "Epoch [10/10], Loss: 40.9123, Accuracy: 0.5785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "8kKPUfid2R70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for lstm_data, cnn_data, labels in test_loader:\n",
        "        lstm_data, cnn_data, labels = lstm_data.to(device), cnn_data.to(device), labels.to(device)\n",
        "        output = model(lstm_data, cnn_data)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7YtQXUL2QQc",
        "outputId": "b985c27c-64d5-4f25-afd0-b29c3c93d0b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNAlxxRU3HFG"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}